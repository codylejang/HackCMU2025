{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 3, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 67, "column": 0}, "map": {"version":3,"sources":["file:///Users/hyunwooyi/Documents/Projects/HackCMU2025/src/lib/database.ts"],"sourcesContent":["import fs from 'fs';\nimport path from 'path';\n\nexport interface Book {\n  id: string;\n  title: string;\n  author?: string;\n  fileType: 'pdf' | 'epub' | 'txt';\n  uploadDate: string;\n  filePath: string;\n  coverPath?: string;\n  fileSize: number;\n  content?: string;\n  currentPage?: number;\n}\n\nconst DATABASE_PATH = path.join(process.cwd(), 'data', 'database', 'books.json');\n\n// Ensure database file exists\nfunction ensureDatabaseExists() {\n  const dbDir = path.dirname(DATABASE_PATH);\n  if (!fs.existsSync(dbDir)) {\n    fs.mkdirSync(dbDir, { recursive: true });\n  }\n  \n  if (!fs.existsSync(DATABASE_PATH)) {\n    fs.writeFileSync(DATABASE_PATH, JSON.stringify([], null, 2));\n  }\n}\n\n// Read all books from database\nexport function getAllBooks(): Book[] {\n  ensureDatabaseExists();\n  try {\n    const data = fs.readFileSync(DATABASE_PATH, 'utf8');\n    return JSON.parse(data);\n  } catch (error) {\n    console.error('Error reading books database:', error);\n    return [];\n  }\n}\n\n// Get a single book by ID\nexport function getBookById(id: string): Book | null {\n  const books = getAllBooks();\n  return books.find(book => book.id === id) || null;\n}\n\n// Add a new book to database\nexport function addBook(book: Book): Book {\n  ensureDatabaseExists();\n  const books = getAllBooks();\n  books.push(book);\n  fs.writeFileSync(DATABASE_PATH, JSON.stringify(books, null, 2));\n  return book;\n}\n\n// Update an existing book\nexport function updateBook(id: string, updates: Partial<Book>): Book | null {\n  ensureDatabaseExists();\n  const books = getAllBooks();\n  const index = books.findIndex(book => book.id === id);\n  \n  if (index === -1) {\n    return null;\n  }\n  \n  books[index] = { ...books[index], ...updates };\n  fs.writeFileSync(DATABASE_PATH, JSON.stringify(books, null, 2));\n  return books[index];\n}\n\n// Delete a book from database\nexport function deleteBook(id: string): boolean {\n  ensureDatabaseExists();\n  const books = getAllBooks();\n  const index = books.findIndex(book => book.id === id);\n  \n  if (index === -1) {\n    return false;\n  }\n  \n  const book = books[index];\n  \n  // Remove the book from array\n  books.splice(index, 1);\n  fs.writeFileSync(DATABASE_PATH, JSON.stringify(books, null, 2));\n  \n  // Delete associated files\n  try {\n    if (fs.existsSync(book.filePath)) {\n      fs.unlinkSync(book.filePath);\n    }\n    if (book.coverPath && fs.existsSync(book.coverPath)) {\n      fs.unlinkSync(book.coverPath);\n    }\n  } catch (error) {\n    console.error('Error deleting book files:', error);\n  }\n  \n  return true;\n}\n\n// Generate unique filename\nexport function generateUniqueFilename(originalName: string): string {\n  const timestamp = Date.now();\n  const random = Math.random().toString(36).substring(2, 8);\n  const ext = path.extname(originalName);\n  const name = path.basename(originalName, ext);\n  return `${name}_${timestamp}_${random}${ext}`;\n}\n\n// Generate book ID\nexport function generateBookId(): string {\n  return `book_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAAA;AACA;;;AAeA,MAAM,gBAAgB,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI,QAAQ,YAAY;AAEnE,8BAA8B;AAC9B,SAAS;IACP,MAAM,QAAQ,4GAAI,CAAC,OAAO,CAAC;IAC3B,IAAI,CAAC,wGAAE,CAAC,UAAU,CAAC,QAAQ;QACzB,wGAAE,CAAC,SAAS,CAAC,OAAO;YAAE,WAAW;QAAK;IACxC;IAEA,IAAI,CAAC,wGAAE,CAAC,UAAU,CAAC,gBAAgB;QACjC,wGAAE,CAAC,aAAa,CAAC,eAAe,KAAK,SAAS,CAAC,EAAE,EAAE,MAAM;IAC3D;AACF;AAGO,SAAS;IACd;IACA,IAAI;QACF,MAAM,OAAO,wGAAE,CAAC,YAAY,CAAC,eAAe;QAC5C,OAAO,KAAK,KAAK,CAAC;IACpB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,iCAAiC;QAC/C,OAAO,EAAE;IACX;AACF;AAGO,SAAS,YAAY,EAAU;IACpC,MAAM,QAAQ;IACd,OAAO,MAAM,IAAI,CAAC,CAAA,OAAQ,KAAK,EAAE,KAAK,OAAO;AAC/C;AAGO,SAAS,QAAQ,IAAU;IAChC;IACA,MAAM,QAAQ;IACd,MAAM,IAAI,CAAC;IACX,wGAAE,CAAC,aAAa,CAAC,eAAe,KAAK,SAAS,CAAC,OAAO,MAAM;IAC5D,OAAO;AACT;AAGO,SAAS,WAAW,EAAU,EAAE,OAAsB;IAC3D;IACA,MAAM,QAAQ;IACd,MAAM,QAAQ,MAAM,SAAS,CAAC,CAAA,OAAQ,KAAK,EAAE,KAAK;IAElD,IAAI,UAAU,CAAC,GAAG;QAChB,OAAO;IACT;IAEA,KAAK,CAAC,MAAM,GAAG;QAAE,GAAG,KAAK,CAAC,MAAM;QAAE,GAAG,OAAO;IAAC;IAC7C,wGAAE,CAAC,aAAa,CAAC,eAAe,KAAK,SAAS,CAAC,OAAO,MAAM;IAC5D,OAAO,KAAK,CAAC,MAAM;AACrB;AAGO,SAAS,WAAW,EAAU;IACnC;IACA,MAAM,QAAQ;IACd,MAAM,QAAQ,MAAM,SAAS,CAAC,CAAA,OAAQ,KAAK,EAAE,KAAK;IAElD,IAAI,UAAU,CAAC,GAAG;QAChB,OAAO;IACT;IAEA,MAAM,OAAO,KAAK,CAAC,MAAM;IAEzB,6BAA6B;IAC7B,MAAM,MAAM,CAAC,OAAO;IACpB,wGAAE,CAAC,aAAa,CAAC,eAAe,KAAK,SAAS,CAAC,OAAO,MAAM;IAE5D,0BAA0B;IAC1B,IAAI;QACF,IAAI,wGAAE,CAAC,UAAU,CAAC,KAAK,QAAQ,GAAG;YAChC,wGAAE,CAAC,UAAU,CAAC,KAAK,QAAQ;QAC7B;QACA,IAAI,KAAK,SAAS,IAAI,wGAAE,CAAC,UAAU,CAAC,KAAK,SAAS,GAAG;YACnD,wGAAE,CAAC,UAAU,CAAC,KAAK,SAAS;QAC9B;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,8BAA8B;IAC9C;IAEA,OAAO;AACT;AAGO,SAAS,uBAAuB,YAAoB;IACzD,MAAM,YAAY,KAAK,GAAG;IAC1B,MAAM,SAAS,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,SAAS,CAAC,GAAG;IACvD,MAAM,MAAM,4GAAI,CAAC,OAAO,CAAC;IACzB,MAAM,OAAO,4GAAI,CAAC,QAAQ,CAAC,cAAc;IACzC,OAAO,GAAG,KAAK,CAAC,EAAE,UAAU,CAAC,EAAE,SAAS,KAAK;AAC/C;AAGO,SAAS;IACd,OAAO,CAAC,KAAK,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,SAAS,CAAC,GAAG,IAAI;AAC3E","debugId":null}},
    {"offset": {"line": 227, "column": 0}, "map": {"version":3,"sources":["file:///Users/hyunwooyi/Documents/Projects/HackCMU2025/src/lib/fileUpload.ts"],"sourcesContent":["import fs from 'fs';\nimport path from 'path';\nimport { generateUniqueFilename, generateBookId } from './database';\n\nexport interface UploadResult {\n  success: boolean;\n  bookId?: string;\n  filePath?: string;\n  coverPath?: string;\n  error?: string;\n}\n\n// Save uploaded file to data/books directory\nexport async function saveUploadedFile(file: File): Promise<UploadResult> {\n  try {\n    // Ensure data/books directory exists\n    const booksDir = path.join(process.cwd(), 'data', 'books');\n    if (!fs.existsSync(booksDir)) {\n      fs.mkdirSync(booksDir, { recursive: true });\n    }\n\n    // Generate unique filename\n    const uniqueFilename = generateUniqueFilename(file.name);\n    const filePath = path.join(booksDir, uniqueFilename);\n    \n    // Convert File to Buffer and save\n    const bytes = await file.arrayBuffer();\n    const buffer = Buffer.from(bytes);\n    \n    fs.writeFileSync(filePath, buffer);\n    \n    // Generate cover path (we'll create a simple cover later)\n    const coversDir = path.join(process.cwd(), 'data', 'covers');\n    if (!fs.existsSync(coversDir)) {\n      fs.mkdirSync(coversDir, { recursive: true });\n    }\n    \n    // Use PNG for PDF and EPUB covers, SVG for others\n    const coverExtension = (file.type === 'application/pdf' || file.type === 'application/epub+zip') ? '.png' : '.svg';\n    const coverFilename = uniqueFilename.replace(/\\.[^/.]+$/, coverExtension);\n    const coverPath = path.join(coversDir, coverFilename);\n    \n    return {\n      success: true,\n      bookId: generateBookId(),\n      filePath,\n      coverPath\n    };\n  } catch (error) {\n    console.error('Error saving uploaded file:', error);\n    return {\n      success: false,\n      error: 'Failed to save uploaded file'\n    };\n  }\n}\n\n// Extract PDF cover page as image\nexport async function extractPDFCover(\n  pdfPath: string,\n  coverPath: string\n): Promise<boolean> {\n  try {\n    const { exec } = require('child_process');\n    const util = require('util');\n    const execAsync = util.promisify(exec);\n    \n    // Use pdftoppm directly for more reliable conversion\n    const tempOutputPath = path.join(path.dirname(coverPath), 'temp_cover');\n    const command = `pdftoppm -png -f 1 -l 1 -scale-to 300 \"${pdfPath}\" \"${tempOutputPath}\"`;\n    \n    console.log('Executing command:', command);\n    const { stdout, stderr } = await execAsync(command);\n    \n    if (stderr) {\n      console.log('pdftoppm stderr:', stderr);\n    }\n    \n    // Find the generated file\n    const generatedFiles = fs.readdirSync(path.dirname(coverPath))\n      .filter(file => file.startsWith('temp_cover') && file.endsWith('.png'));\n    \n    if (generatedFiles.length > 0) {\n      const generatedFile = path.join(path.dirname(coverPath), generatedFiles[0]);\n      \n      // Rename to our target cover path\n      if (fs.existsSync(generatedFile)) {\n        fs.renameSync(generatedFile, coverPath);\n        console.log(`PDF cover extracted successfully: ${coverPath}`);\n        return true;\n      }\n    }\n    \n    console.log('PDF cover extraction failed, no image generated');\n    return false;\n  } catch (error) {\n    console.error('Error extracting PDF cover:', error);\n    return false;\n  }\n}\n\n// Extract EPUB cover image\nexport async function extractEPUBCover(\n  epubPath: string,\n  coverPath: string\n): Promise<boolean> {\n  try {\n    const sharp = require('sharp');\n    const { exec } = require('child_process');\n    const util = require('util');\n    const execAsync = util.promisify(exec);\n    \n    // First, list the contents of the EPUB to find cover images\n    const listCommand = `unzip -l \"${epubPath}\"`;\n    console.log('Listing EPUB contents:', listCommand);\n    \n    const { stdout: listOutput } = await execAsync(listCommand);\n    console.log('EPUB contents:', listOutput);\n    \n    // Look for cover images in the file listing\n    const coverPatterns = [\n      /cover\\.(jpg|jpeg|png|gif)/i,\n      /title\\.(jpg|jpeg|png|gif)/i,\n      /front\\.(jpg|jpeg|png|gif)/i,\n      /.*cover.*\\.(jpg|jpeg|png|gif)/i,\n      /.*title.*\\.(jpg|jpeg|png|gif)/i,\n      /.*front.*\\.(jpg|jpeg|png|gif)/i\n    ];\n    \n    let coverImagePath = null;\n    const lines = listOutput.split('\\n');\n    \n    for (const line of lines) {\n      for (const pattern of coverPatterns) {\n        const match = line.match(pattern);\n        if (match) {\n          // Extract the full path from the line\n          const parts = line.trim().split(/\\s+/);\n          if (parts.length >= 4) {\n            coverImagePath = parts[parts.length - 1];\n            console.log('Found potential cover image:', coverImagePath);\n            break;\n          }\n        }\n      }\n      if (coverImagePath) break;\n    }\n    \n    // If no cover found by pattern, look for any image file\n    if (!coverImagePath) {\n      const imagePattern = /\\.(jpg|jpeg|png|gif)$/i;\n      for (const line of lines) {\n        const match = line.match(imagePattern);\n        if (match) {\n          const parts = line.trim().split(/\\s+/);\n          if (parts.length >= 4) {\n            coverImagePath = parts[parts.length - 1];\n            console.log('Using first image as cover:', coverImagePath);\n            break;\n          }\n        }\n      }\n    }\n    \n    if (!coverImagePath) {\n      console.log('No cover image found in EPUB');\n      return false;\n    }\n    \n    // Extract the cover image\n    const tempDir = path.join(path.dirname(coverPath), 'temp_epub_extract');\n    if (!fs.existsSync(tempDir)) {\n      fs.mkdirSync(tempDir, { recursive: true });\n    }\n    \n    const extractCommand = `unzip -j \"${epubPath}\" \"${coverImagePath}\" -d \"${tempDir}\"`;\n    console.log('Extracting cover image:', extractCommand);\n    \n    await execAsync(extractCommand);\n    \n    // Find the extracted file\n    const extractedFiles = fs.readdirSync(tempDir);\n    if (extractedFiles.length === 0) {\n      console.log('No files extracted from EPUB');\n      return false;\n    }\n    \n    const extractedFile = path.join(tempDir, extractedFiles[0]);\n    console.log('Extracted file:', extractedFile);\n    \n    // Process the image with Sharp\n    try {\n      const resizedImage = await sharp(extractedFile)\n        .resize(300, 400, {\n          fit: 'contain',\n          background: { r: 255, g: 255, b: 255, alpha: 1 }\n        })\n        .png()\n        .toBuffer();\n      \n      // Save the resized image\n      fs.writeFileSync(coverPath, resizedImage);\n      console.log(`EPUB cover extracted successfully: ${coverPath}`);\n      \n      // Clean up temp directory\n      fs.rmSync(tempDir, { recursive: true, force: true });\n      \n      return true;\n    } catch (sharpError) {\n      console.error('Error processing EPUB cover with Sharp:', sharpError);\n      \n      // Clean up temp directory\n      fs.rmSync(tempDir, { recursive: true, force: true });\n      \n      return false;\n    }\n  } catch (error) {\n    console.error('Error extracting EPUB cover:', error);\n    return false;\n  }\n}\n\n// Generate a simple cover image (placeholder)\nexport async function generateBookCover(\n  title: string, \n  fileType: string, \n  coverPath: string,\n  filePath?: string\n): Promise<boolean> {\n  try {\n    // For PDFs, try to extract the cover page first\n    if (fileType === 'pdf' && filePath) {\n      const coverExtracted = await extractPDFCover(filePath, coverPath);\n      if (coverExtracted) {\n        return true;\n      }\n      console.log('PDF cover extraction failed, falling back to generated cover');\n      \n      // If PDF extraction failed, change the cover path to SVG\n      const svgCoverPath = coverPath.replace('.png', '.svg');\n      coverPath = svgCoverPath;\n    }\n    \n    // For EPUBs, try to extract the cover image first\n    if (fileType === 'epub' && filePath) {\n      const coverExtracted = await extractEPUBCover(filePath, coverPath);\n      if (coverExtracted) {\n        return true;\n      }\n      console.log('EPUB cover extraction failed, falling back to generated cover');\n      \n      // If EPUB extraction failed, change the cover path to SVG\n      const svgCoverPath = coverPath.replace('.png', '.svg');\n      coverPath = svgCoverPath;\n    }\n\n    // Create an enhanced SVG cover with better styling\n    const coverContent = `\n    <svg width=\"300\" height=\"400\" xmlns=\"http://www.w3.org/2000/svg\">\n      <defs>\n        <linearGradient id=\"grad1\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n          <stop offset=\"0%\" style=\"stop-color:#fbbf24;stop-opacity:1\" />\n          <stop offset=\"100%\" style=\"stop-color:#f59e0b;stop-opacity:1\" />\n        </linearGradient>\n        <filter id=\"shadow\" x=\"-20%\" y=\"-20%\" width=\"140%\" height=\"140%\">\n          <feDropShadow dx=\"2\" dy=\"2\" stdDeviation=\"3\" flood-color=\"#000000\" flood-opacity=\"0.3\"/>\n        </filter>\n      </defs>\n      <rect width=\"300\" height=\"400\" fill=\"url(#grad1)\" filter=\"url(#shadow)\"/>\n      <rect x=\"20\" y=\"20\" width=\"260\" height=\"360\" fill=\"white\" stroke=\"#d97706\" stroke-width=\"2\" rx=\"8\"/>\n      <text x=\"150\" y=\"60\" text-anchor=\"middle\" font-family=\"Arial, sans-serif\" font-size=\"18\" font-weight=\"bold\" fill=\"#1f2937\">\n        ${title.length > 25 ? title.substring(0, 25) + '...' : title}\n      </text>\n      <text x=\"150\" y=\"200\" text-anchor=\"middle\" font-family=\"Arial, sans-serif\" font-size=\"64\" fill=\"#f59e0b\">\n        ${getFileIcon(fileType)}\n      </text>\n      <text x=\"150\" y=\"250\" text-anchor=\"middle\" font-family=\"Arial, sans-serif\" font-size=\"14\" font-weight=\"bold\" fill=\"#f59e0b\">\n        ${fileType.toUpperCase()}\n      </text>\n    </svg>`;\n    \n    fs.writeFileSync(coverPath, coverContent);\n    return true;\n  } catch (error) {\n    console.error('Error generating book cover:', error);\n    return false;\n  }\n}\n\n// Get file icon based on file type\nfunction getFileIcon(fileType: string): string {\n  switch (fileType.toLowerCase()) {\n    case 'pdf':\n      return 'üìÑ';\n    case 'epub':\n      return 'üìö';\n    case 'txt':\n      return 'üìù';\n    default:\n      return 'üìñ';\n  }\n}\n\n// Extract text content from file with proper PDF and EPUB support\nexport async function extractTextContent(filePath: string, fileType: string): Promise<string> {\n  try {\n    if (fileType === 'txt') {\n      try {\n        if (!fs.existsSync(filePath)) {\n          throw new Error(`TXT file not found: ${filePath}`);\n        }\n        \n        const content = fs.readFileSync(filePath, 'utf8');\n        \n        if (!content || content.trim().length === 0) {\n          return `# Text Document\\n\\n**File:** ${path.basename(filePath)}\\n\\n**Status:** Empty text file.\\n\\n**File Size:** ${(fs.statSync(filePath).size / 1024).toFixed(2)} KB\\n\\n**Note:** This text file appears to be empty.`;\n        }\n        \n        return content;\n      } catch (error) {\n        console.error('TXT file reading error:', error);\n        return `# Text Document\\n\\n**File:** ${path.basename(filePath)}\\n\\n**Status:** Error reading text file.\\n\\n**Error:** ${error instanceof Error ? error.message : 'Unknown error'}\\n\\n**Note:** This text file could not be read. It may be corrupted or in an unsupported encoding.`;\n      }\n    } else if (fileType === 'pdf') {\n      try {\n        // Use pdf-parse for PDF parsing (Node.js compatible)\n        const pdfParse = require('pdf-parse');\n        \n        // Check if file exists\n        if (!fs.existsSync(filePath)) {\n          throw new Error(`PDF file not found: ${filePath}`);\n        }\n        \n        console.log(`Processing PDF file: ${filePath}`);\n        const dataBuffer = fs.readFileSync(filePath);\n        console.log(`PDF file size: ${dataBuffer.length} bytes`);\n        \n        // Parse the PDF\n        const data = await pdfParse(dataBuffer);\n        console.log(`PDF text extracted: ${data.text ? data.text.length : 0} characters`);\n        \n        if (!data.text || data.text.trim().length === 0) {\n          return `# PDF Document\\n\\n**File:** ${path.basename(filePath)}\\n\\n**Status:** PDF file processed but no text content could be extracted. This may be a scanned PDF or image-based document.\\n\\n**File Size:** ${(fs.statSync(filePath).size / 1024 / 1024).toFixed(2)} MB\\n\\n**Pages:** ${data.numpages || 'Unknown'}\\n\\n**Note:** For scanned PDFs, OCR (Optical Character Recognition) would be needed to extract text content.`;\n        }\n        \n        return data.text.trim();\n      } catch (error) {\n        console.error('PDF parsing error:', error);\n        return `# PDF Document\\n\\n**File:** ${path.basename(filePath)}\\n\\n**Status:** Error processing PDF file.\\n\\n**Error:** ${error instanceof Error ? error.message : 'Unknown error'}\\n\\n**File Size:** ${fs.existsSync(filePath) ? (fs.statSync(filePath).size / 1024 / 1024).toFixed(2) + ' MB' : 'Unknown'}\\n\\n**Note:** This PDF file could not be processed. It may be corrupted, password-protected, or in an unsupported format.`;\n      }\n    } else if (fileType === 'epub') {\n      try {\n        const epub = require('epub');\n        \n        return new Promise((resolve, reject) => {\n          const epubInstance = new epub(filePath);\n          \n          epubInstance.on('end', () => {\n            let fullText = '';\n            \n            // Add book metadata\n            if (epubInstance.metadata) {\n              if (epubInstance.metadata.title) {\n                fullText += `# ${epubInstance.metadata.title}\\n\\n`;\n              }\n              if (epubInstance.metadata.creator) {\n                fullText += `**Author:** ${epubInstance.metadata.creator}\\n\\n`;\n              }\n              if (epubInstance.metadata.description) {\n                fullText += `**Description:** ${epubInstance.metadata.description}\\n\\n`;\n              }\n              if (epubInstance.metadata.publisher) {\n                fullText += `**Publisher:** ${epubInstance.metadata.publisher}\\n\\n`;\n              }\n              if (epubInstance.metadata.date) {\n                fullText += `**Date:** ${epubInstance.metadata.date}\\n\\n`;\n              }\n            }\n            \n            // Get the flow (chapters) and table of contents\n            const flow = epubInstance.flow || [];\n            const toc = epubInstance.toc || [];\n            \n            // Determine the reading order - prefer TOC if available, otherwise use flow\n            const readingOrder = toc.length > 0 ? toc : flow;\n            \n            // Add table of contents\n            if (readingOrder.length > 0) {\n              fullText += `## Table of Contents\\n\\n`;\n              readingOrder.forEach((item: any, index: number) => {\n                const title = item.title || item.label || item.name || `Chapter ${index + 1}`;\n                fullText += `${index + 1}. ${title}\\n`;\n              });\n              fullText += '\\n---\\n\\n';\n            }\n              \n            // Extract chapter content using the reading order\n            const maxChapters = readingOrder.length;\n            \n            const extractChapterContent = (chapterIndex: number) => {\n              if (chapterIndex >= maxChapters) {\n                // Add file information\n                fullText += `## File Information\\n\\n`;\n                fullText += `- **Original File:** ${path.basename(filePath)}\\n`;\n                fullText += `- **File Size:** ${(fs.statSync(filePath).size / 1024 / 1024).toFixed(2)} MB\\n`;\n                fullText += `- **Upload Date:** ${new Date().toLocaleDateString()}\\n`;\n                fullText += `- **Total Chapters:** ${maxChapters}\\n\\n`;\n                \n                // Add note about content extraction\n                fullText += `## Note\\n\\n`;\n                fullText += `This EPUB file has been successfully parsed and its structure extracted. The table of contents and metadata are available. All ${maxChapters} chapters have been fully extracted with complete content.`;\n                \n                // All chapters processed, resolve the promise\n                resolve(fullText);\n                return;\n              }\n              \n              const readingItem = readingOrder[chapterIndex];\n              const chapterTitle = readingItem.title || readingItem.label || readingItem.name || `Chapter ${chapterIndex + 1}`;\n              \n              fullText += `## ${chapterTitle}\\n\\n`;\n              \n              // Find the corresponding chapter in flow by ID or title\n              let chapter = null;\n              if (readingItem.id) {\n                chapter = flow.find((item: any) => item.id === readingItem.id);\n              } else if (readingItem.href) {\n                chapter = flow.find((item: any) => item.href === readingItem.href);\n              } else {\n                // Fallback to index if no ID or href\n                chapter = flow[chapterIndex];\n              }\n              \n              if (chapter && chapter.id) {\n                epubInstance.getChapter(chapter.id, (error: any, text: string) => {\n                  if (error) {\n                    fullText += `*Error loading chapter content: ${error.message}*\\n\\n`;\n                  } else if (text) {\n                    // Clean up the text content with better formatting\n                    let cleanText = text\n                      .replace(/<[^>]*>/g, '') // Remove HTML tags\n                      .replace(/\\s+/g, ' ') // Normalize whitespace\n                      .trim();\n                    \n                    if (cleanText.length > 0) {\n                      // Remove duplicate chapter title from content\n                      const normalizedChapterTitle = chapterTitle.toLowerCase().replace(/[^\\w\\s]/g, '').trim();\n                      const normalizedContent = cleanText.toLowerCase().replace(/[^\\w\\s]/g, '').trim();\n                      \n                      // Check if content starts with the chapter title\n                      if (normalizedContent.startsWith(normalizedChapterTitle)) {\n                        // Find the end of the title in the original text\n                        const titleMatch = cleanText.match(new RegExp(`^${chapterTitle.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&')}\\\\s*`, 'i'));\n                        if (titleMatch) {\n                          cleanText = cleanText.substring(titleMatch[0].length).trim();\n                        }\n                      }\n                      \n                      // Improve paragraph formatting\n                      cleanText = cleanText\n                        .replace(/\\s*\\.\\s*/g, '. ') // Fix sentence spacing\n                        .replace(/\\s*,\\s*/g, ', ') // Fix comma spacing\n                        .replace(/\\s*;\\s*/g, '; ') // Fix semicolon spacing\n                        .replace(/\\s*:\\s*/g, ': ') // Fix colon spacing\n                        .replace(/\\s*!\\s*/g, '! ') // Fix exclamation spacing\n                        .replace(/\\s*\\?\\s*/g, '? ') // Fix question spacing\n                        .replace(/\\s+/g, ' ') // Normalize whitespace again\n                        .trim();\n                      \n                      // Add paragraph breaks for better readability\n                      const paragraphs = cleanText.split(/(?<=[.!?])\\s+(?=[A-Z])/);\n                      const formattedParagraphs = paragraphs\n                        .map(p => p.trim())\n                        .filter(p => p.length > 0)\n                        .join('\\n\\n');\n                      \n                      // Add the full content without truncation\n                      fullText += formattedParagraphs;\n                    } else {\n                      fullText += `*Chapter content could not be extracted.*`;\n                    }\n                  } else {\n                    fullText += `*Chapter content is not available.*`;\n                  }\n                  fullText += '\\n\\n';\n                  \n                  // Process next chapter\n                  extractChapterContent(chapterIndex + 1);\n                });\n              } else {\n                fullText += `*Chapter content could not be loaded.*\\n\\n`;\n                // Process next chapter\n                extractChapterContent(chapterIndex + 1);\n              }\n            };\n            \n            // Start extracting chapters\n            if (readingOrder.length > 0) {\n              extractChapterContent(0);\n            } else {\n              fullText += 'No chapters found in this EPUB file.\\n\\n';\n              resolve(fullText);\n            }\n          });\n          \n          epubInstance.on('error', (err: any) => {\n            console.error('EPUB parsing error:', err);\n            const fallbackText = `# EPUB Document\\n\\n**File:** ${path.basename(filePath)}\\n\\n**Status:** Error parsing EPUB file.\\n\\n**Error:** ${err.message}\\n\\n**File Size:** ${(fs.statSync(filePath).size / 1024 / 1024).toFixed(2)} MB\\n\\n**Note:** This EPUB file could not be parsed. It may be corrupted or in an unsupported format.`;\n            resolve(fallbackText);\n          });\n          \n          epubInstance.parse();\n        });\n      } catch (error) {\n        console.error('EPUB processing error:', error);\n        return `# EPUB Document\\n\\n**File:** ${path.basename(filePath)}\\n\\n**Status:** Error processing EPUB file.\\n\\n**Error:** ${error instanceof Error ? error.message : 'Unknown error'}\\n\\n**File Size:** ${fs.existsSync(filePath) ? (fs.statSync(filePath).size / 1024 / 1024).toFixed(2) + ' MB' : 'Unknown'}\\n\\n**Note:** This EPUB file could not be processed.`;\n      }\n    }\n    return 'Content extraction not available for this file type.';\n  } catch (error) {\n    console.error('Error extracting text content:', error);\n    return 'Error extracting content from file.';\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAAA;AACA;AACA;;;;AAWO,eAAe,iBAAiB,IAAU;IAC/C,IAAI;QACF,qCAAqC;QACrC,MAAM,WAAW,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI,QAAQ;QAClD,IAAI,CAAC,wGAAE,CAAC,UAAU,CAAC,WAAW;YAC5B,wGAAE,CAAC,SAAS,CAAC,UAAU;gBAAE,WAAW;YAAK;QAC3C;QAEA,2BAA2B;QAC3B,MAAM,iBAAiB,IAAA,kJAAsB,EAAC,KAAK,IAAI;QACvD,MAAM,WAAW,4GAAI,CAAC,IAAI,CAAC,UAAU;QAErC,kCAAkC;QAClC,MAAM,QAAQ,MAAM,KAAK,WAAW;QACpC,MAAM,SAAS,OAAO,IAAI,CAAC;QAE3B,wGAAE,CAAC,aAAa,CAAC,UAAU;QAE3B,0DAA0D;QAC1D,MAAM,YAAY,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI,QAAQ;QACnD,IAAI,CAAC,wGAAE,CAAC,UAAU,CAAC,YAAY;YAC7B,wGAAE,CAAC,SAAS,CAAC,WAAW;gBAAE,WAAW;YAAK;QAC5C;QAEA,kDAAkD;QAClD,MAAM,iBAAiB,AAAC,KAAK,IAAI,KAAK,qBAAqB,KAAK,IAAI,KAAK,yBAA0B,SAAS;QAC5G,MAAM,gBAAgB,eAAe,OAAO,CAAC,aAAa;QAC1D,MAAM,YAAY,4GAAI,CAAC,IAAI,CAAC,WAAW;QAEvC,OAAO;YACL,SAAS;YACT,QAAQ,IAAA,0IAAc;YACtB;YACA;QACF;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,+BAA+B;QAC7C,OAAO;YACL,SAAS;YACT,OAAO;QACT;IACF;AACF;AAGO,eAAe,gBACpB,OAAe,EACf,SAAiB;IAEjB,IAAI;QACF,MAAM,EAAE,IAAI,EAAE;QACd,MAAM;QACN,MAAM,YAAY,KAAK,SAAS,CAAC;QAEjC,qDAAqD;QACrD,MAAM,iBAAiB,4GAAI,CAAC,IAAI,CAAC,4GAAI,CAAC,OAAO,CAAC,YAAY;QAC1D,MAAM,UAAU,CAAC,uCAAuC,EAAE,QAAQ,GAAG,EAAE,eAAe,CAAC,CAAC;QAExF,QAAQ,GAAG,CAAC,sBAAsB;QAClC,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,UAAU;QAE3C,IAAI,QAAQ;YACV,QAAQ,GAAG,CAAC,oBAAoB;QAClC;QAEA,0BAA0B;QAC1B,MAAM,iBAAiB,wGAAE,CAAC,WAAW,CAAC,4GAAI,CAAC,OAAO,CAAC,YAChD,MAAM,CAAC,CAAA,OAAQ,KAAK,UAAU,CAAC,iBAAiB,KAAK,QAAQ,CAAC;QAEjE,IAAI,eAAe,MAAM,GAAG,GAAG;YAC7B,MAAM,gBAAgB,4GAAI,CAAC,IAAI,CAAC,4GAAI,CAAC,OAAO,CAAC,YAAY,cAAc,CAAC,EAAE;YAE1E,kCAAkC;YAClC,IAAI,wGAAE,CAAC,UAAU,CAAC,gBAAgB;gBAChC,wGAAE,CAAC,UAAU,CAAC,eAAe;gBAC7B,QAAQ,GAAG,CAAC,CAAC,kCAAkC,EAAE,WAAW;gBAC5D,OAAO;YACT;QACF;QAEA,QAAQ,GAAG,CAAC;QACZ,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,+BAA+B;QAC7C,OAAO;IACT;AACF;AAGO,eAAe,iBACpB,QAAgB,EAChB,SAAiB;IAEjB,IAAI;QACF,MAAM;QACN,MAAM,EAAE,IAAI,EAAE;QACd,MAAM;QACN,MAAM,YAAY,KAAK,SAAS,CAAC;QAEjC,4DAA4D;QAC5D,MAAM,cAAc,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC;QAC5C,QAAQ,GAAG,CAAC,0BAA0B;QAEtC,MAAM,EAAE,QAAQ,UAAU,EAAE,GAAG,MAAM,UAAU;QAC/C,QAAQ,GAAG,CAAC,kBAAkB;QAE9B,4CAA4C;QAC5C,MAAM,gBAAgB;YACpB;YACA;YACA;YACA;YACA;YACA;SACD;QAED,IAAI,iBAAiB;QACrB,MAAM,QAAQ,WAAW,KAAK,CAAC;QAE/B,KAAK,MAAM,QAAQ,MAAO;YACxB,KAAK,MAAM,WAAW,cAAe;gBACnC,MAAM,QAAQ,KAAK,KAAK,CAAC;gBACzB,IAAI,OAAO;oBACT,sCAAsC;oBACtC,MAAM,QAAQ,KAAK,IAAI,GAAG,KAAK,CAAC;oBAChC,IAAI,MAAM,MAAM,IAAI,GAAG;wBACrB,iBAAiB,KAAK,CAAC,MAAM,MAAM,GAAG,EAAE;wBACxC,QAAQ,GAAG,CAAC,gCAAgC;wBAC5C;oBACF;gBACF;YACF;YACA,IAAI,gBAAgB;QACtB;QAEA,wDAAwD;QACxD,IAAI,CAAC,gBAAgB;YACnB,MAAM,eAAe;YACrB,KAAK,MAAM,QAAQ,MAAO;gBACxB,MAAM,QAAQ,KAAK,KAAK,CAAC;gBACzB,IAAI,OAAO;oBACT,MAAM,QAAQ,KAAK,IAAI,GAAG,KAAK,CAAC;oBAChC,IAAI,MAAM,MAAM,IAAI,GAAG;wBACrB,iBAAiB,KAAK,CAAC,MAAM,MAAM,GAAG,EAAE;wBACxC,QAAQ,GAAG,CAAC,+BAA+B;wBAC3C;oBACF;gBACF;YACF;QACF;QAEA,IAAI,CAAC,gBAAgB;YACnB,QAAQ,GAAG,CAAC;YACZ,OAAO;QACT;QAEA,0BAA0B;QAC1B,MAAM,UAAU,4GAAI,CAAC,IAAI,CAAC,4GAAI,CAAC,OAAO,CAAC,YAAY;QACnD,IAAI,CAAC,wGAAE,CAAC,UAAU,CAAC,UAAU;YAC3B,wGAAE,CAAC,SAAS,CAAC,SAAS;gBAAE,WAAW;YAAK;QAC1C;QAEA,MAAM,iBAAiB,CAAC,UAAU,EAAE,SAAS,GAAG,EAAE,eAAe,MAAM,EAAE,QAAQ,CAAC,CAAC;QACnF,QAAQ,GAAG,CAAC,2BAA2B;QAEvC,MAAM,UAAU;QAEhB,0BAA0B;QAC1B,MAAM,iBAAiB,wGAAE,CAAC,WAAW,CAAC;QACtC,IAAI,eAAe,MAAM,KAAK,GAAG;YAC/B,QAAQ,GAAG,CAAC;YACZ,OAAO;QACT;QAEA,MAAM,gBAAgB,4GAAI,CAAC,IAAI,CAAC,SAAS,cAAc,CAAC,EAAE;QAC1D,QAAQ,GAAG,CAAC,mBAAmB;QAE/B,+BAA+B;QAC/B,IAAI;YACF,MAAM,eAAe,MAAM,MAAM,eAC9B,MAAM,CAAC,KAAK,KAAK;gBAChB,KAAK;gBACL,YAAY;oBAAE,GAAG;oBAAK,GAAG;oBAAK,GAAG;oBAAK,OAAO;gBAAE;YACjD,GACC,GAAG,GACH,QAAQ;YAEX,yBAAyB;YACzB,wGAAE,CAAC,aAAa,CAAC,WAAW;YAC5B,QAAQ,GAAG,CAAC,CAAC,mCAAmC,EAAE,WAAW;YAE7D,0BAA0B;YAC1B,wGAAE,CAAC,MAAM,CAAC,SAAS;gBAAE,WAAW;gBAAM,OAAO;YAAK;YAElD,OAAO;QACT,EAAE,OAAO,YAAY;YACnB,QAAQ,KAAK,CAAC,2CAA2C;YAEzD,0BAA0B;YAC1B,wGAAE,CAAC,MAAM,CAAC,SAAS;gBAAE,WAAW;gBAAM,OAAO;YAAK;YAElD,OAAO;QACT;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,gCAAgC;QAC9C,OAAO;IACT;AACF;AAGO,eAAe,kBACpB,KAAa,EACb,QAAgB,EAChB,SAAiB,EACjB,QAAiB;IAEjB,IAAI;QACF,gDAAgD;QAChD,IAAI,aAAa,SAAS,UAAU;YAClC,MAAM,iBAAiB,MAAM,gBAAgB,UAAU;YACvD,IAAI,gBAAgB;gBAClB,OAAO;YACT;YACA,QAAQ,GAAG,CAAC;YAEZ,yDAAyD;YACzD,MAAM,eAAe,UAAU,OAAO,CAAC,QAAQ;YAC/C,YAAY;QACd;QAEA,kDAAkD;QAClD,IAAI,aAAa,UAAU,UAAU;YACnC,MAAM,iBAAiB,MAAM,iBAAiB,UAAU;YACxD,IAAI,gBAAgB;gBAClB,OAAO;YACT;YACA,QAAQ,GAAG,CAAC;YAEZ,0DAA0D;YAC1D,MAAM,eAAe,UAAU,OAAO,CAAC,QAAQ;YAC/C,YAAY;QACd;QAEA,mDAAmD;QACnD,MAAM,eAAe,CAAC;;;;;;;;;;;;;;QAclB,EAAE,MAAM,MAAM,GAAG,KAAK,MAAM,SAAS,CAAC,GAAG,MAAM,QAAQ,MAAM;;;QAG7D,EAAE,YAAY,UAAU;;;QAGxB,EAAE,SAAS,WAAW,GAAG;;UAEvB,CAAC;QAEP,wGAAE,CAAC,aAAa,CAAC,WAAW;QAC5B,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,gCAAgC;QAC9C,OAAO;IACT;AACF;AAEA,mCAAmC;AACnC,SAAS,YAAY,QAAgB;IACnC,OAAQ,SAAS,WAAW;QAC1B,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT;YACE,OAAO;IACX;AACF;AAGO,eAAe,mBAAmB,QAAgB,EAAE,QAAgB;IACzE,IAAI;QACF,IAAI,aAAa,OAAO;YACtB,IAAI;gBACF,IAAI,CAAC,wGAAE,CAAC,UAAU,CAAC,WAAW;oBAC5B,MAAM,IAAI,MAAM,CAAC,oBAAoB,EAAE,UAAU;gBACnD;gBAEA,MAAM,UAAU,wGAAE,CAAC,YAAY,CAAC,UAAU;gBAE1C,IAAI,CAAC,WAAW,QAAQ,IAAI,GAAG,MAAM,KAAK,GAAG;oBAC3C,OAAO,CAAC,6BAA6B,EAAE,4GAAI,CAAC,QAAQ,CAAC,UAAU,mDAAmD,EAAE,CAAC,wGAAE,CAAC,QAAQ,CAAC,UAAU,IAAI,GAAG,IAAI,EAAE,OAAO,CAAC,GAAG,oDAAoD,CAAC;gBAC1N;gBAEA,OAAO;YACT,EAAE,OAAO,OAAO;gBACd,QAAQ,KAAK,CAAC,2BAA2B;gBACzC,OAAO,CAAC,6BAA6B,EAAE,4GAAI,CAAC,QAAQ,CAAC,UAAU,uDAAuD,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,gBAAgB,kGAAkG,CAAC;YACtR;QACF,OAAO,IAAI,aAAa,OAAO;YAC7B,IAAI;gBACF,qDAAqD;gBACrD,MAAM;gBAEN,uBAAuB;gBACvB,IAAI,CAAC,wGAAE,CAAC,UAAU,CAAC,WAAW;oBAC5B,MAAM,IAAI,MAAM,CAAC,oBAAoB,EAAE,UAAU;gBACnD;gBAEA,QAAQ,GAAG,CAAC,CAAC,qBAAqB,EAAE,UAAU;gBAC9C,MAAM,aAAa,wGAAE,CAAC,YAAY,CAAC;gBACnC,QAAQ,GAAG,CAAC,CAAC,eAAe,EAAE,WAAW,MAAM,CAAC,MAAM,CAAC;gBAEvD,gBAAgB;gBAChB,MAAM,OAAO,MAAM,SAAS;gBAC5B,QAAQ,GAAG,CAAC,CAAC,oBAAoB,EAAE,KAAK,IAAI,GAAG,KAAK,IAAI,CAAC,MAAM,GAAG,EAAE,WAAW,CAAC;gBAEhF,IAAI,CAAC,KAAK,IAAI,IAAI,KAAK,IAAI,CAAC,IAAI,GAAG,MAAM,KAAK,GAAG;oBAC/C,OAAO,CAAC,4BAA4B,EAAE,4GAAI,CAAC,QAAQ,CAAC,UAAU,gJAAgJ,EAAE,CAAC,wGAAE,CAAC,QAAQ,CAAC,UAAU,IAAI,GAAG,OAAO,IAAI,EAAE,OAAO,CAAC,GAAG,kBAAkB,EAAE,KAAK,QAAQ,IAAI,UAAU,4GAA4G,CAAC;gBACpa;gBAEA,OAAO,KAAK,IAAI,CAAC,IAAI;YACvB,EAAE,OAAO,OAAO;gBACd,QAAQ,KAAK,CAAC,sBAAsB;gBACpC,OAAO,CAAC,4BAA4B,EAAE,4GAAI,CAAC,QAAQ,CAAC,UAAU,yDAAyD,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,gBAAgB,mBAAmB,EAAE,wGAAE,CAAC,UAAU,CAAC,YAAY,CAAC,wGAAE,CAAC,QAAQ,CAAC,UAAU,IAAI,GAAG,OAAO,IAAI,EAAE,OAAO,CAAC,KAAK,QAAQ,UAAU,yHAAyH,CAAC;YACva;QACF,OAAO,IAAI,aAAa,QAAQ;YAC9B,IAAI;gBACF,MAAM;gBAEN,OAAO,IAAI,QAAQ,CAAC,SAAS;oBAC3B,MAAM,eAAe,IAAI,KAAK;oBAE9B,aAAa,EAAE,CAAC,OAAO;wBACrB,IAAI,WAAW;wBAEf,oBAAoB;wBACpB,IAAI,aAAa,QAAQ,EAAE;4BACzB,IAAI,aAAa,QAAQ,CAAC,KAAK,EAAE;gCAC/B,YAAY,CAAC,EAAE,EAAE,aAAa,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC;4BACpD;4BACA,IAAI,aAAa,QAAQ,CAAC,OAAO,EAAE;gCACjC,YAAY,CAAC,YAAY,EAAE,aAAa,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC;4BAChE;4BACA,IAAI,aAAa,QAAQ,CAAC,WAAW,EAAE;gCACrC,YAAY,CAAC,iBAAiB,EAAE,aAAa,QAAQ,CAAC,WAAW,CAAC,IAAI,CAAC;4BACzE;4BACA,IAAI,aAAa,QAAQ,CAAC,SAAS,EAAE;gCACnC,YAAY,CAAC,eAAe,EAAE,aAAa,QAAQ,CAAC,SAAS,CAAC,IAAI,CAAC;4BACrE;4BACA,IAAI,aAAa,QAAQ,CAAC,IAAI,EAAE;gCAC9B,YAAY,CAAC,UAAU,EAAE,aAAa,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC;4BAC3D;wBACF;wBAEA,gDAAgD;wBAChD,MAAM,OAAO,aAAa,IAAI,IAAI,EAAE;wBACpC,MAAM,MAAM,aAAa,GAAG,IAAI,EAAE;wBAElC,4EAA4E;wBAC5E,MAAM,eAAe,IAAI,MAAM,GAAG,IAAI,MAAM;wBAE5C,wBAAwB;wBACxB,IAAI,aAAa,MAAM,GAAG,GAAG;4BAC3B,YAAY,CAAC,wBAAwB,CAAC;4BACtC,aAAa,OAAO,CAAC,CAAC,MAAW;gCAC/B,MAAM,QAAQ,KAAK,KAAK,IAAI,KAAK,KAAK,IAAI,KAAK,IAAI,IAAI,CAAC,QAAQ,EAAE,QAAQ,GAAG;gCAC7E,YAAY,GAAG,QAAQ,EAAE,EAAE,EAAE,MAAM,EAAE,CAAC;4BACxC;4BACA,YAAY;wBACd;wBAEA,kDAAkD;wBAClD,MAAM,cAAc,aAAa,MAAM;wBAEvC,MAAM,wBAAwB,CAAC;4BAC7B,IAAI,gBAAgB,aAAa;gCAC/B,uBAAuB;gCACvB,YAAY,CAAC,uBAAuB,CAAC;gCACrC,YAAY,CAAC,qBAAqB,EAAE,4GAAI,CAAC,QAAQ,CAAC,UAAU,EAAE,CAAC;gCAC/D,YAAY,CAAC,iBAAiB,EAAE,CAAC,wGAAE,CAAC,QAAQ,CAAC,UAAU,IAAI,GAAG,OAAO,IAAI,EAAE,OAAO,CAAC,GAAG,KAAK,CAAC;gCAC5F,YAAY,CAAC,mBAAmB,EAAE,IAAI,OAAO,kBAAkB,GAAG,EAAE,CAAC;gCACrE,YAAY,CAAC,sBAAsB,EAAE,YAAY,IAAI,CAAC;gCAEtD,oCAAoC;gCACpC,YAAY,CAAC,WAAW,CAAC;gCACzB,YAAY,CAAC,+HAA+H,EAAE,YAAY,0DAA0D,CAAC;gCAErN,8CAA8C;gCAC9C,QAAQ;gCACR;4BACF;4BAEA,MAAM,cAAc,YAAY,CAAC,aAAa;4BAC9C,MAAM,eAAe,YAAY,KAAK,IAAI,YAAY,KAAK,IAAI,YAAY,IAAI,IAAI,CAAC,QAAQ,EAAE,eAAe,GAAG;4BAEhH,YAAY,CAAC,GAAG,EAAE,aAAa,IAAI,CAAC;4BAEpC,wDAAwD;4BACxD,IAAI,UAAU;4BACd,IAAI,YAAY,EAAE,EAAE;gCAClB,UAAU,KAAK,IAAI,CAAC,CAAC,OAAc,KAAK,EAAE,KAAK,YAAY,EAAE;4BAC/D,OAAO,IAAI,YAAY,IAAI,EAAE;gCAC3B,UAAU,KAAK,IAAI,CAAC,CAAC,OAAc,KAAK,IAAI,KAAK,YAAY,IAAI;4BACnE,OAAO;gCACL,qCAAqC;gCACrC,UAAU,IAAI,CAAC,aAAa;4BAC9B;4BAEA,IAAI,WAAW,QAAQ,EAAE,EAAE;gCACzB,aAAa,UAAU,CAAC,QAAQ,EAAE,EAAE,CAAC,OAAY;oCAC/C,IAAI,OAAO;wCACT,YAAY,CAAC,gCAAgC,EAAE,MAAM,OAAO,CAAC,KAAK,CAAC;oCACrE,OAAO,IAAI,MAAM;wCACf,mDAAmD;wCACnD,IAAI,YAAY,KACb,OAAO,CAAC,YAAY,IAAI,mBAAmB;yCAC3C,OAAO,CAAC,QAAQ,KAAK,uBAAuB;yCAC5C,IAAI;wCAEP,IAAI,UAAU,MAAM,GAAG,GAAG;4CACxB,8CAA8C;4CAC9C,MAAM,yBAAyB,aAAa,WAAW,GAAG,OAAO,CAAC,YAAY,IAAI,IAAI;4CACtF,MAAM,oBAAoB,UAAU,WAAW,GAAG,OAAO,CAAC,YAAY,IAAI,IAAI;4CAE9E,iDAAiD;4CACjD,IAAI,kBAAkB,UAAU,CAAC,yBAAyB;gDACxD,iDAAiD;gDACjD,MAAM,aAAa,UAAU,KAAK,CAAC,IAAI,OAAO,CAAC,CAAC,EAAE,aAAa,OAAO,CAAC,uBAAuB,QAAQ,IAAI,CAAC,EAAE;gDAC7G,IAAI,YAAY;oDACd,YAAY,UAAU,SAAS,CAAC,UAAU,CAAC,EAAE,CAAC,MAAM,EAAE,IAAI;gDAC5D;4CACF;4CAEA,+BAA+B;4CAC/B,YAAY,UACT,OAAO,CAAC,aAAa,MAAM,uBAAuB;6CAClD,OAAO,CAAC,YAAY,MAAM,oBAAoB;6CAC9C,OAAO,CAAC,YAAY,MAAM,wBAAwB;6CAClD,OAAO,CAAC,YAAY,MAAM,oBAAoB;6CAC9C,OAAO,CAAC,YAAY,MAAM,0BAA0B;6CACpD,OAAO,CAAC,aAAa,MAAM,uBAAuB;6CAClD,OAAO,CAAC,QAAQ,KAAK,6BAA6B;6CAClD,IAAI;4CAEP,8CAA8C;4CAC9C,MAAM,aAAa,UAAU,KAAK,CAAC;4CACnC,MAAM,sBAAsB,WACzB,GAAG,CAAC,CAAA,IAAK,EAAE,IAAI,IACf,MAAM,CAAC,CAAA,IAAK,EAAE,MAAM,GAAG,GACvB,IAAI,CAAC;4CAER,0CAA0C;4CAC1C,YAAY;wCACd,OAAO;4CACL,YAAY,CAAC,yCAAyC,CAAC;wCACzD;oCACF,OAAO;wCACL,YAAY,CAAC,mCAAmC,CAAC;oCACnD;oCACA,YAAY;oCAEZ,uBAAuB;oCACvB,sBAAsB,eAAe;gCACvC;4BACF,OAAO;gCACL,YAAY,CAAC,0CAA0C,CAAC;gCACxD,uBAAuB;gCACvB,sBAAsB,eAAe;4BACvC;wBACF;wBAEA,4BAA4B;wBAC5B,IAAI,aAAa,MAAM,GAAG,GAAG;4BAC3B,sBAAsB;wBACxB,OAAO;4BACL,YAAY;4BACZ,QAAQ;wBACV;oBACF;oBAEA,aAAa,EAAE,CAAC,SAAS,CAAC;wBACxB,QAAQ,KAAK,CAAC,uBAAuB;wBACrC,MAAM,eAAe,CAAC,6BAA6B,EAAE,4GAAI,CAAC,QAAQ,CAAC,UAAU,uDAAuD,EAAE,IAAI,OAAO,CAAC,mBAAmB,EAAE,CAAC,wGAAE,CAAC,QAAQ,CAAC,UAAU,IAAI,GAAG,OAAO,IAAI,EAAE,OAAO,CAAC,GAAG,qGAAqG,CAAC;wBACnU,QAAQ;oBACV;oBAEA,aAAa,KAAK;gBACpB;YACF,EAAE,OAAO,OAAO;gBACd,QAAQ,KAAK,CAAC,0BAA0B;gBACxC,OAAO,CAAC,6BAA6B,EAAE,4GAAI,CAAC,QAAQ,CAAC,UAAU,0DAA0D,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,gBAAgB,mBAAmB,EAAE,wGAAE,CAAC,UAAU,CAAC,YAAY,CAAC,wGAAE,CAAC,QAAQ,CAAC,UAAU,IAAI,GAAG,OAAO,IAAI,EAAE,OAAO,CAAC,KAAK,QAAQ,UAAU,oDAAoD,CAAC;YACpW;QACF;QACA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,OAAO;IACT;AACF","debugId":null}},
    {"offset": {"line": 681, "column": 0}, "map": {"version":3,"sources":["file:///Users/hyunwooyi/Documents/Projects/HackCMU2025/src/app/api/books/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\nimport { getAllBooks, addBook, deleteBook } from '@/lib/database';\nimport { saveUploadedFile, generateBookCover, extractTextContent } from '@/lib/fileUpload';\nimport path from 'path';\n\nexport async function GET() {\n  try {\n    const books = getAllBooks();\n    return NextResponse.json({\n      success: true,\n      data: books\n    });\n  } catch (error) {\n    console.error('Error fetching books:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to fetch books' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function POST(request: NextRequest) {\n  try {\n    const formData = await request.formData();\n    const file = formData.get('file') as File;\n    const author = formData.get('author') as string;\n    \n    if (!file) {\n      return NextResponse.json(\n        { success: false, error: 'No file provided' },\n        { status: 400 }\n      );\n    }\n\n    // Validate file type\n    const allowedTypes = ['application/pdf', 'application/epub+zip', 'text/plain'];\n    if (!allowedTypes.includes(file.type)) {\n      return NextResponse.json(\n        { success: false, error: 'Invalid file type. Only PDF, EPUB, and TXT files are allowed.' },\n        { status: 400 }\n      );\n    }\n\n    // Validate file size (10MB limit)\n    const maxSize = 10 * 1024 * 1024; // 10MB\n    if (file.size > maxSize) {\n      return NextResponse.json(\n        { success: false, error: 'File size too large. Maximum size is 10MB.' },\n        { status: 400 }\n      );\n    }\n\n    // Save the uploaded file\n    const uploadResult = await saveUploadedFile(file);\n    if (!uploadResult.success) {\n      return NextResponse.json(\n        { success: false, error: uploadResult.error || 'Failed to save file' },\n        { status: 500 }\n      );\n    }\n\n    // Determine file type\n    const fileType = file.type === 'application/pdf' ? 'pdf' : \n                    file.type === 'application/epub+zip' ? 'epub' : 'txt';\n\n    // Extract text content with error handling\n    let content: string;\n    try {\n      content = await extractTextContent(uploadResult.filePath!, fileType);\n    } catch (error) {\n      console.error('Content extraction failed:', error);\n      content = `# ${file.name}\\n\\n**Error:** Content extraction failed.\\n\\n**Details:** ${error instanceof Error ? error.message : 'Unknown error'}\\n\\n**File Type:** ${fileType.toUpperCase()}\\n\\n**Note:** The file was uploaded but content could not be extracted.`;\n    }\n\n    // Generate book cover with error handling\n    const title = file.name.replace(/\\.[^/.]+$/, \"\");\n    let finalCoverPath = uploadResult.coverPath!;\n    try {\n      const coverGenerated = await generateBookCover(title, fileType, uploadResult.coverPath!, uploadResult.filePath);\n      if (coverGenerated) {\n        // Check if the cover path was changed (e.g., from PNG to SVG for failed extraction)\n        const expectedExtension = (fileType === 'pdf' || fileType === 'epub') ? '.png' : '.svg';\n        const actualExtension = path.extname(uploadResult.coverPath!);\n        if (actualExtension !== expectedExtension) {\n          // Update the cover path to match the actual file created\n          finalCoverPath = uploadResult.coverPath!.replace(actualExtension, expectedExtension);\n        }\n      }\n    } catch (error) {\n      console.error('Cover generation failed:', error);\n      // Continue without cover - the system will handle missing covers gracefully\n    }\n\n    // Create book record\n    const newBook = {\n      id: uploadResult.bookId!,\n      title,\n      author: author || 'Unknown',\n      fileType: fileType as 'pdf' | 'epub' | 'txt',\n      uploadDate: new Date().toISOString(),\n      filePath: uploadResult.filePath!,\n      coverPath: finalCoverPath || '', // Use the final cover path\n      fileSize: file.size,\n      content,\n      currentPage: 1 // Initialize to page 1\n    };\n\n    // Save to database\n    const savedBook = addBook(newBook);\n\n    return NextResponse.json({\n      success: true,\n      data: savedBook\n    });\n  } catch (error) {\n    console.error('Error uploading book:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to upload book' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function DELETE(request: NextRequest) {\n  try {\n    const { searchParams } = new URL(request.url);\n    const bookId = searchParams.get('id');\n    \n    if (!bookId) {\n      return NextResponse.json(\n        { success: false, error: 'Book ID is required' },\n        { status: 400 }\n      );\n    }\n\n    const success = deleteBook(bookId);\n    if (!success) {\n      return NextResponse.json(\n        { success: false, error: 'Book not found' },\n        { status: 404 }\n      );\n    }\n\n    return NextResponse.json({\n      success: true,\n      message: 'Book deleted successfully'\n    });\n  } catch (error) {\n    console.error('Error deleting book:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to delete book' },\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;AACA;;;;;AAEO,eAAe;IACpB,IAAI;QACF,MAAM,QAAQ,IAAA,uIAAW;QACzB,OAAO,gJAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,MAAM;QACR;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,yBAAyB;QACvC,OAAO,gJAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAAwB,GACjD;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,WAAW,MAAM,QAAQ,QAAQ;QACvC,MAAM,OAAO,SAAS,GAAG,CAAC;QAC1B,MAAM,SAAS,SAAS,GAAG,CAAC;QAE5B,IAAI,CAAC,MAAM;YACT,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO;YAAmB,GAC5C;gBAAE,QAAQ;YAAI;QAElB;QAEA,qBAAqB;QACrB,MAAM,eAAe;YAAC;YAAmB;YAAwB;SAAa;QAC9E,IAAI,CAAC,aAAa,QAAQ,CAAC,KAAK,IAAI,GAAG;YACrC,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO;YAAgE,GACzF;gBAAE,QAAQ;YAAI;QAElB;QAEA,kCAAkC;QAClC,MAAM,UAAU,KAAK,OAAO,MAAM,OAAO;QACzC,IAAI,KAAK,IAAI,GAAG,SAAS;YACvB,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO;YAA6C,GACtE;gBAAE,QAAQ;YAAI;QAElB;QAEA,yBAAyB;QACzB,MAAM,eAAe,MAAM,IAAA,8IAAgB,EAAC;QAC5C,IAAI,CAAC,aAAa,OAAO,EAAE;YACzB,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO,aAAa,KAAK,IAAI;YAAsB,GACrE;gBAAE,QAAQ;YAAI;QAElB;QAEA,sBAAsB;QACtB,MAAM,WAAW,KAAK,IAAI,KAAK,oBAAoB,QACnC,KAAK,IAAI,KAAK,yBAAyB,SAAS;QAEhE,2CAA2C;QAC3C,IAAI;QACJ,IAAI;YACF,UAAU,MAAM,IAAA,gJAAkB,EAAC,aAAa,QAAQ,EAAG;QAC7D,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,8BAA8B;YAC5C,UAAU,CAAC,EAAE,EAAE,KAAK,IAAI,CAAC,0DAA0D,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,gBAAgB,mBAAmB,EAAE,SAAS,WAAW,GAAG,uEAAuE,CAAC;QACpQ;QAEA,0CAA0C;QAC1C,MAAM,QAAQ,KAAK,IAAI,CAAC,OAAO,CAAC,aAAa;QAC7C,IAAI,iBAAiB,aAAa,SAAS;QAC3C,IAAI;YACF,MAAM,iBAAiB,MAAM,IAAA,+IAAiB,EAAC,OAAO,UAAU,aAAa,SAAS,EAAG,aAAa,QAAQ;YAC9G,IAAI,gBAAgB;gBAClB,oFAAoF;gBACpF,MAAM,oBAAoB,AAAC,aAAa,SAAS,aAAa,SAAU,SAAS;gBACjF,MAAM,kBAAkB,4GAAI,CAAC,OAAO,CAAC,aAAa,SAAS;gBAC3D,IAAI,oBAAoB,mBAAmB;oBACzC,yDAAyD;oBACzD,iBAAiB,aAAa,SAAS,CAAE,OAAO,CAAC,iBAAiB;gBACpE;YACF;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,4BAA4B;QAC1C,4EAA4E;QAC9E;QAEA,qBAAqB;QACrB,MAAM,UAAU;YACd,IAAI,aAAa,MAAM;YACvB;YACA,QAAQ,UAAU;YAClB,UAAU;YACV,YAAY,IAAI,OAAO,WAAW;YAClC,UAAU,aAAa,QAAQ;YAC/B,WAAW,kBAAkB;YAC7B,UAAU,KAAK,IAAI;YACnB;YACA,aAAa,EAAE,uBAAuB;QACxC;QAEA,mBAAmB;QACnB,MAAM,YAAY,IAAA,mIAAO,EAAC;QAE1B,OAAO,gJAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,MAAM;QACR;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,yBAAyB;QACvC,OAAO,gJAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAAwB,GACjD;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe,OAAO,OAAoB;IAC/C,IAAI;QACF,MAAM,EAAE,YAAY,EAAE,GAAG,IAAI,IAAI,QAAQ,GAAG;QAC5C,MAAM,SAAS,aAAa,GAAG,CAAC;QAEhC,IAAI,CAAC,QAAQ;YACX,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO;YAAsB,GAC/C;gBAAE,QAAQ;YAAI;QAElB;QAEA,MAAM,UAAU,IAAA,sIAAU,EAAC;QAC3B,IAAI,CAAC,SAAS;YACZ,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO;YAAiB,GAC1C;gBAAE,QAAQ;YAAI;QAElB;QAEA,OAAO,gJAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,SAAS;QACX;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,wBAAwB;QACtC,OAAO,gJAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAAwB,GACjD;YAAE,QAAQ;QAAI;IAElB;AACF","debugId":null}}]
}